{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractive Long Form Question Answering System for Annual Reports using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the brand statement of TCS?\""
      ],
      "metadata": {
        "id": "7RuTm1U7WFno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACTING TEXT FROM PDF"
      ],
      "metadata": {
        "id": "_exM5acL1wRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfminer.six\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REea6NOpTXDl",
        "outputId": "991fe4ee-5377-4d66-f260-fed902ddf89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-36.0.0 pdfminer.six-20211012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pdf2text.py /content/tcs.pdf >> converted_text.txt"
      ],
      "metadata": {
        "id": "OusqvzyVUi5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the text."
      ],
      "metadata": {
        "id": "gpxBlEvWLfVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "f1_new = open('/content/converted_text.txt', 'r')\n",
        "f1_old = open('cleaned_text.txt', 'w')\n",
        "#f1_beside = open('out3.txt', 'w')\n",
        "lines = f1_new.readlines()\n",
        "#print(lines)\n",
        "\n",
        "for line in range(len(lines)):\n",
        "  if(len(lines[line])>10 and re.search('[a-zA-Z]', lines[line]) and '|' not in lines[line]) :\n",
        "\n",
        "      if (len(lines[line+1])>10):\n",
        "          f1_old.write(lines[line].strip('\\n'))\n",
        "      elif (len(lines[line-1])>10 and re.search('[a-zA-Z]', lines[line-1]) and '|' not in lines[line-1]) and (len(lines[line+1]) < 10 and re.search('[a-zA-Z]', lines[line+1])) :\n",
        "       \n",
        "            f1_old.write(lines[line].strip('\\n'))\n",
        "            f1_old.write(lines[line+1].strip('\\n')+'\\n')\n",
        "            \n",
        "      elif (len(lines[line-1])>10 and re.search('[a-zA-Z]', lines[line-1]) and '|' not in lines[line-1]):\n",
        "\n",
        "            f1_old.write(lines[line].strip('\\n')+'\\n')"
      ],
      "metadata": {
        "id": "zZIbb3d71zLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using nltk to tokenize or separate the text into sentences."
      ],
      "metadata": {
        "id": "nvodDxOvLmjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  \n",
        "nltk.download('punkt')\n",
        "f_1 = open('/content/cleaned_text.txt', 'r')\n",
        "f_out = open('sentence_separated.txt', 'w')\n",
        "all_1 = f_1.readlines()\n",
        "all_sentences_text = []\n",
        "for i in all_1:\n",
        "  sentences = nltk.sent_tokenize(i)\n",
        "  for j in sentences:\n",
        "    j = j.replace(',', '')\n",
        "    j = j.replace('-', ' ')\n",
        "    # f_out.write(j+'\\n')\n",
        "    all_sentences_text.append(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoqRVoGC6Ygl",
        "outputId": "d44e8fd6-0bff-4558-b27c-b93583899774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "L9Szaa6C8ACA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the TF-IDF Vectorizer and cosine similarity to compare all the sentences to the question and obtaining the top 200 sentences that are closest to the question. "
      ],
      "metadata": {
        "id": "p52eoIR8L6pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "all_sentences_text.append(re.sub(r\"[^a-zA-Z0-9]+\", ' ', question))\n",
        "tfidf = TfidfVectorizer().fit_transform(all_sentences_text)\n",
        "pairwise_similarity = tfidf * tfidf.T\n",
        "arr =  pairwise_similarity.toarray() \n",
        "temp = list(arr[len(arr)-1]).copy()\n",
        "temp.sort(reverse= True)\n",
        "to_finbert = []\n",
        "for i in range(200):\n",
        "  to_finbert.append(all_sentences_text[list(arr[len(arr)-1]).index(temp[i])])"
      ],
      "metadata": {
        "id": "EIN4vz6s8B6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINBERT"
      ],
      "metadata": {
        "id": "3my9ub_ESza3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the finbert embeddings of the sentences and the question and once again use cosine similarity to rank the sentences by their distance from the question. Using finbert embedding lends financial context and just overall more contextual understanding than TF-IDF vectorizer."
      ],
      "metadata": {
        "id": "3uWEOG-VM-Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install finbert-embedding==0.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C3uc8_fZSB-",
        "outputId": "c6504321-17f1-45ec-f529-1ec85b403d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting finbert-embedding==0.1.4\n",
            "  Downloading finbert_embedding-0.1.4-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from finbert-embedding==0.1.4) (2.7.0)\n",
            "Collecting torch==1.1.0\n",
            "  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9 MB 4.2 kB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2019.12.20)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.21-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 73.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.24.0,>=1.23.21\n",
            "  Downloading botocore-1.23.21-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 54.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 87.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2021.10.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (12.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.2)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.42.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->finbert-embedding==0.1.4) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.1.1)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, torch, boto3, pytorch-pretrained-bert, finbert-embedding\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "y\n",
            "n\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.1.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.1.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.1.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.21 botocore-1.23.21 finbert-embedding-0.1.4 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 torch-1.1.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wrapt --upgrade --ignore-installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdfnKOtOXVuJ",
        "outputId": "019f1d48-f8aa-45b0-ff4d-71f163f24e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrapt\n",
            "  Downloading wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 20 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 30 kB 43.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 40 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 51 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 61 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 71 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 79 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: wrapt\n",
            "Successfully installed wrapt-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install finbert-embedding==0.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INic9NP3XYTe",
        "outputId": "f89f46c3-c2c2-402b-f699-501b6a9683de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: finbert-embedding==0.1.4 in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pytorch-pretrained-bert==0.6.2 in /usr/local/lib/python3.7/dist-packages (from finbert-embedding==0.1.4) (0.6.2)\n",
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.7/dist-packages (from finbert-embedding==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.20.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.19.5)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.21 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.23.21)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.21->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.10)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.22.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.13.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.42.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->finbert-embedding==0.1.4) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->finbert-embedding==0.1.4) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from finbert_embedding.embedding import FinbertEmbedding\n",
        "finbert = FinbertEmbedding()"
      ],
      "metadata": {
        "id": "Z46mHUiDNmAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "X = question\n",
        "vectorX = finbert.sentence_vector(X)\n",
        "\n",
        "scores = list()\n",
        "\n",
        "for line in to_finbert:\n",
        "\n",
        "  Y = line\n",
        "  vectorY = finbert.sentence_vector(Y)\n",
        "  scores.append([Y, 1 - spatial.distance.cosine(vectorY, vectorX)])"
      ],
      "metadata": {
        "id": "XO4JpTo4Bbja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores.sort(key = lambda x: x[1], reverse=True)\n",
        "input_to_json_bert = open('input_to_json_bert.json','w' )\n",
        "top_k_sentences = []\n",
        "for i in range(20):\n",
        "  top_k_sentences.append(scores[i][0])"
      ],
      "metadata": {
        "id": "9RxhhSPoNDt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = \"The IRS Guidance pertaining to the subject. Best I can say is business expense deductible. But it depends on what it is you want to deduct. Taxpayer are considered “traveling away from home” if their duties. \""
      ],
      "metadata": {
        "id": "JeNTn0iAQ1W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(top_k_sentences)):\n",
        "  top_k_sentences[i] = x+top_k_sentences[i]"
      ],
      "metadata": {
        "id": "Wgh-_7u6Qef5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top k sentences after comparing finbert embeddings:"
      ],
      "metadata": {
        "id": "tGN7QRkbN2KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NghYDgdfkYTX",
        "outputId": "2d8154be-7172-409c-d583-abe5e0154083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is the brand statement of TCS ',\n",
              " 'WHAT DOES YOUR NEW BRAND STATEMENT `BUILDING ON BELIEF’ MEAN TO YOU AND TO CUSTOMERS?',\n",
              " 'TCS adopted a new brand statement Building on Belief to convey how its partnership with customers goes beyond technology deployment.',\n",
              " 'WHAT ARE TALENT CLOUDS AND HOW DO THEY CHANGE THE DELIVERY MODEL?',\n",
              " 'What is your company’s direct contribution to community development projects  Amount in INR and the details of the projects undertaken?',\n",
              " 'In that context the new brand statement is very timely and reflects that aspiration.',\n",
              " 'WHAT ROLE DOES YOUR INTELLECTUAL PROPERTY PRODUCTS AND PLATFORMS PLAY IN THE G&T OPPORTUNITY?',\n",
              " 'To better articulate its mission and its aspirations your company adopted a new brand statement this year `Building on Belief’.',\n",
              " 'If explanations provided here are found to be different from what is described in the Company’s periodic financial statements (not limited to Notes to Accounts) then the definition provided in the certified financial statements will prevail.',\n",
              " 'TCS Research marked its 40th year by adopting a new brand identity with the tagline `Inventing for Impact’.',\n",
              " 'I think it describes what TCS does very accurately and also reflects the ethos of the Tata Group and its evolution over the last century and a half.',\n",
              " 'Ernst & Young has assured the data presented under GRI Standards disclosures as specified in their Assurance Statement.',\n",
              " 'The new statement conveys how TCS builds on their ambition and optimism to transform their business for the better the impact of which is felt by their customers and the communities they serve.',\n",
              " 'The specific carbon footprint data is presented for the sake of continuity and is not comparable with the prior years.',\n",
              " 'TCS is committed to using zero ',\n",
              " 'This is why the new brand statement resonates so well and feels so right.',\n",
              " 'KAK: In the second scenario TCS Research & Innovation is a catalyst.',\n",
              " 'over and above what is mandated as per local laws?',\n",
              " 'For details of meetings of the Board please refer to the Corporate Governance Report which is a part of this report.',\n",
              " 'If yes what steps have been taken to improve their capacity and capability of local and small vendors?']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = dict()\n",
        "json_data[\"version\"] = \"v1\"\n",
        "json_paragraphs = list()\n",
        "\n",
        "for i in range(len(top_k_sentences)):\n",
        "  json_paragraph = {\"qas\":[{\"question\":question, \"id\":1, \n",
        "                            \"answers\":[{\"text\":\"An answer\", \"answer_start\":0}], \n",
        "                            \"is_impossible\": \"false\"}], \"context\":top_k_sentences[i]}\n",
        "  json_paragraphs.append(json_paragraph)\n",
        "\n",
        "json_data[\"data\"] = [{\"title\":\"TCS\", \"paragraphs\":json_paragraphs}]"
      ],
      "metadata": {
        "id": "lKTsbl1qPnfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('json_data.json', 'w') as f:\n",
        "  f.write(str(json_data))"
      ],
      "metadata": {
        "id": "vpf0yQcLPwvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT"
      ],
      "metadata": {
        "id": "mYff0NDhSerP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section deals with downloading a pre-trained (on unlabelled annual report text) + finetuned (on FiQA) BERT model to rank your sentences to answer the question instead of similarity. In other words, the BERT model aids in ranking the sentence based on how well it answers the question. We then take the top 5 of those sentences and present them as an answer, thus completing the extractive long form question answering system using BERT.\n",
        "\n",
        "\n",
        "If you do not have your own pre-trained and fine-tuned BERT you can use the already fine-tuned question answering BERT models on hugging face. They yield very good results. This notebook has the continuing code. \n",
        "\n",
        "\n",
        "If you want to pre-train and fine-tune your model please visit this notebook."
      ],
      "metadata": {
        "id": "fgTH5RebOFdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cTIQpfi9Sgxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358abea1-b3b0-41a0-fc97-3f7972629f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "id": "iUWWRLsWSkSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02797a9d-0a87-450b-cdef-733bae84d7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n"
      ],
      "metadata": {
        "id": "4TDGXU_LSm7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd079e0-241f-46c1-e0b4-f0c8a063d7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-08 05:07:22--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.128, 142.250.153.128, 142.250.145.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   173MB/s    in 2.2s    \n",
            "\n",
            "2021-12-08 05:07:25 (173 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/uncased_L-12_H-768_A-12.zip"
      ],
      "metadata": {
        "id": "Gg9nzoSBSpOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0b3e7d-1b77-4f38-93df-fa945f25c6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ]
    }
  ]
}